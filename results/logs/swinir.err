/home/woody/iwi5/iwi5293h/software/private/conda/envs/thesis-gpu/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/woody/iwi5/iwi5293h/software/private/conda/envs/thesis-gpu/lib/python3.10/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025831440/work/aten/src/ATen/native/TensorShape.cpp:3549.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/woody/iwi5/iwi5293h/software/private/conda/envs/thesis-gpu/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
/home/woody/iwi5/iwi5293h/software/private/conda/envs/thesis-gpu/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5293h/Debanjana_Master_Thesis/scripts/train_test_split.py", line 588, in <module>
    main()
  File "/home/hpc/iwi5/iwi5293h/Debanjana_Master_Thesis/scripts/train_test_split.py", line 489, in main
    pred = model(art)
  File "/home/woody/iwi5/iwi5293h/software/private/conda/envs/thesis-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/woody/iwi5/iwi5293h/software/private/conda/envs/thesis-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hpc/iwi5/iwi5293h/Debanjana_Master_Thesis/scripts/train_test_split.py", line 289, in forward
    return self.net(x)
  File "/home/woody/iwi5/iwi5293h/software/private/conda/envs/thesis-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/woody/iwi5/iwi5293h/software/private/conda/envs/thesis-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hpc/iwi5/iwi5293h/Debanjana_Master_Thesis/SwinIR/models/network_swinir.py", line 835, in forward
    res = self.conv_after_body(self.forward_features(x_first)) + x_first
  File "/home/hpc/iwi5/iwi5293h/Debanjana_Master_Thesis/SwinIR/models/network_swinir.py", line 798, in forward_features
    x = layer(x, x_size)
  File "/home/woody/iwi5/iwi5293h/software/private/conda/envs/thesis-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/woody/iwi5/iwi5293h/software/private/conda/envs/thesis-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hpc/iwi5/iwi5293h/Debanjana_Master_Thesis/SwinIR/models/network_swinir.py", line 482, in forward
    return self.patch_embed(self.conv(self.patch_unembed(self.residual_group(x, x_size), x_size))) + x
  File "/home/woody/iwi5/iwi5293h/software/private/conda/envs/thesis-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/woody/iwi5/iwi5293h/software/private/conda/envs/thesis-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hpc/iwi5/iwi5293h/Debanjana_Master_Thesis/SwinIR/models/network_swinir.py", line 400, in forward
    x = checkpoint.checkpoint(blk, x, x_size)
  File "/home/woody/iwi5/iwi5293h/software/private/conda/envs/thesis-gpu/lib/python3.10/site-packages/torch/_compile.py", line 24, in inner
    return torch._dynamo.disable(fn, recursive)(*args, **kwargs)
  File "/home/woody/iwi5/iwi5293h/software/private/conda/envs/thesis-gpu/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 489, in _fn
    return fn(*args, **kwargs)
  File "/home/woody/iwi5/iwi5293h/software/private/conda/envs/thesis-gpu/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 17, in inner
    return fn(*args, **kwargs)
  File "/home/woody/iwi5/iwi5293h/software/private/conda/envs/thesis-gpu/lib/python3.10/site-packages/torch/utils/checkpoint.py", line 482, in checkpoint
    return CheckpointFunction.apply(function, preserve, *args)
  File "/home/woody/iwi5/iwi5293h/software/private/conda/envs/thesis-gpu/lib/python3.10/site-packages/torch/autograd/function.py", line 553, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/home/woody/iwi5/iwi5293h/software/private/conda/envs/thesis-gpu/lib/python3.10/site-packages/torch/utils/checkpoint.py", line 261, in forward
    outputs = run_function(*args)
  File "/home/woody/iwi5/iwi5293h/software/private/conda/envs/thesis-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/woody/iwi5/iwi5293h/software/private/conda/envs/thesis-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hpc/iwi5/iwi5293h/Debanjana_Master_Thesis/SwinIR/models/network_swinir.py", line 262, in forward
    attn_windows = self.attn(x_windows, mask=self.calculate_mask(x_size).to(x.device))
  File "/home/woody/iwi5/iwi5293h/software/private/conda/envs/thesis-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/woody/iwi5/iwi5293h/software/private/conda/envs/thesis-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hpc/iwi5/iwi5293h/Debanjana_Master_Thesis/SwinIR/models/network_swinir.py", line 124, in forward
    q = q * self.scale
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.22 GiB. GPU 0 has a total capacity of 9.64 GiB of which 48.12 MiB is free. Including non-PyTorch memory, this process has 9.59 GiB memory in use. Of the allocated memory 9.31 GiB is allocated by PyTorch, and 15.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
